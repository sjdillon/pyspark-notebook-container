# pyspark-notebook-container

- run spark and a Jupyter in a container

# Overview

- See this [article](https://levelup.gitconnected.com/using-docker-and-pyspark-134cd4cab867) for details
- the notebook runs in the container
- The purpose of this repo is simply include a docker-compose to make it easy to access the data file

# Getting Started

- clone and start docker to launch notebook

```bash
# clone this repo
git clone https://github.com/sjdillon/pyspark-notebook-container`
# navigate to directory
cd pyspark-notebook-container
# start the docker container
docker-compose up
```
